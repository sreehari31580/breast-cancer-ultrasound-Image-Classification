# Cancer Detection App (PyTorch + Gradâ€‘CAM)

An endâ€‘toâ€‘end breast ultrasound class6) Run the app:
```powershell
streamlit run .\app.py
```
Register a user, log in, upload an image, see prediction + Gradâ€‘CAM, and click "Download PDF Report".

## Analytics Dashboards

### Admin Dashboard ğŸ”
Accessible only to admin users (configured in settings). Provides system-wide analytics:
- **KPIs:** Total users, predictions, average confidence, processing time
- **Time Series:** Daily prediction trends, hourly usage patterns
- **Model Performance:** Class distribution, confidence by class, low-confidence alerts
- **User Activity:** Most active users, engagement metrics

**Configure Admin Users:**
Copy `.env.example` to `.env` and set:
```env
ADMIN_USERS=admin,username1,username2
```

### User Analytics ğŸ“Š
Available to all authenticated users. Shows personal analytics:
- **My Activity:** Total predictions, average confidence, login count
- **Personal Trends:** Daily prediction history, confidence trends over time
- **Class Distribution:** Pie chart of user's predictions by class
- **Recent History:** Detailed table of recent predictions

## Configuration
Tunables live in `src/config/settings.py` or via `.env`:
- **Paths:** `data_raw`, `data_processed`, `models_dir`, `reports_dir`
- **Training:** `img_size`, `batch_size`, `epochs`, `lr`, `seed`
- **Fineâ€‘tuning:** `freeze_backbone`, `unfreeze_last_block`
- **Imbalance:** `use_balanced_sampler` | `use_class_weights`, `class_weight_alpha`
- **App:** `db_path`, `model_version`, `admin_users` (list of admin usernames)
- **Logging:** `log_level` Train a PyTorch CNN (ResNetâ€‘18), run predictions in a Streamlit UI with Gradâ€‘CAM explainability, generate clinicalâ€‘style PDF reports, and keep an auditable SQLite history with user accounts.

## Features
- **Threeâ€‘class classification:** Normal, Benign, Malignant
- **Streamlit UI** with login/registration (bcrypt + SQLite)
- **Gradâ€‘CAM explainability:** Heatmaps targeting ResNet layer4 with overlay
- **PDF Clinical Reports:** Oneâ€‘click download with image, Gradâ€‘CAM, probabilities, model version, timestamp, disclaimer
- **Admin Analytics Dashboard:** System-wide metrics, user activity, model performance monitoring (admin-only)
- **User Analytics:** Personal prediction history, trends, confidence scores, activity breakdown
- **Interactive Visualizations:** Plotly charts for time series, distributions, and comparisons
- **CLI Tools:** preprocess/train/evaluate (Typer)
- **Evaluation Metrics:** Classification report and confusion matrix
- **Production-Ready:** Pydantic Settings config, structured logging, activity tracking

## Tech stack
- **Python 3.13**, Windowsâ€‘friendly
- **Deep Learning:** PyTorch 2.8 + torchvision (ResNetâ€‘18)
- **Web Framework:** Streamlit 1.49+
- **Visualization:** Plotly 5.14+, matplotlib, seaborn
- **Image Processing:** Pillow, OpenCVâ€‘headless
- **Data Science:** scikitâ€‘learn, numpy, pandas
- **Database:** SQLite + bcrypt for secure authentication
- **Configuration:** pydantic/pydanticâ€‘settings, python-dotenv
- **CLI:** Typer
- **PDF Generation:** fpdf2

## Repository layout
```
cancer_detection_app/
â”œâ”€ app.py                  # Streamlit UI
â”œâ”€ cli.py                  # CLI: preprocess/train/evaluate
â”œâ”€ requirements.txt        # Runtime deps
â”œâ”€ pyproject.toml          # Tooling (ruff/black/pytest)
â”œâ”€ src/
â”‚  â”œâ”€ config/settings.py   # Centralized settings
â”‚  â”œâ”€ preprocess.py        # Centerâ€‘crop + resize to 224x224
â”‚  â”œâ”€ train.py             # Train ResNetâ€‘18, save model.pt & class_names.json
â”‚  â”œâ”€ evaluate.py          # Metrics + confusion matrix
â”‚  â””â”€ utils/
â”‚     â”œâ”€ grad_cam.py       # Gradâ€‘CAM hooks & heatmap overlay
â”‚     â”œâ”€ db_utils.py       # SQLite users + predictions
â”‚     â””â”€ reporting/pdf_report.py  # PDF generator
â”œâ”€ data/
â”‚  â”œâ”€ raw/                 # Put Normal/, Benign/, Malignant/ here
â”‚  â””â”€ processed/           # Autoâ€‘generated
â”œâ”€ models/                 # model.pt, class_names.json
â”œâ”€ reports/                # PDFs, Gradâ€‘CAM images, confusion_matrix.png
â””â”€ tests/
	 â””â”€ test_grad_cam.py     # Smoke test
```

## Quickstart (Windows PowerShell)
1) Create a virtual environment and install deps:
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install -r requirements.txt
```

2) Prepare your data:
- Place images under:
	- `data/raw/Normal/`
	- `data/raw/Benign/`
	- `data/raw/Malignant/`

3) (Optional) Preprocess to square+resize:
```powershell
python .\src\preprocess.py
```

4) Train the model:
```powershell
python -m src.train   # or: python .\src\train.py
```
Artifacts are saved to `models/model.pt` and `models/class_names.json`.

5) Evaluate (saves confusion matrix to `reports/`):
```powershell
python -m src.evaluate
```

6) Run the app:
```powershell
streamlit run .\app.py
```
Register a user, log in, upload an image, see prediction + Gradâ€‘CAM, and click â€œDownload PDF Reportâ€.

## Configuration
Tunables live in `src/config/settings.py` or via `.env`:
- Paths: `data_raw`, `data_processed`, `models_dir`, `reports_dir`
- Training: `img_size`, `batch_size`, `epochs`, `lr`, `seed`
- Fineâ€‘tuning: `freeze_backbone`, `unfreeze_last_block`
- Imbalance: `use_balanced_sampler` | `use_class_weights`, `class_weight_alpha`
- App: `db_path`, `model_version`
- Logging: `log_level`

## Development
- Code style: black; Lint: ruff; Tests: pytest.
- Run tests:
```powershell
pytest -q
```

## Troubleshooting
- ModuleNotFoundError: Prefer module mode: `python -m src.train` / `python -m src.evaluate`.
- Torch/vision install issues: ensure versions from `requirements.txt` (Windows + Python 3.13).
- Streamlit DB errors: if schema changed, restart the app (we autoâ€‘migrate columns).

## Security & disclaimers
- Authentication is basic (SQLite + bcrypt); for production, add roles, rate limiting, HTTPS, and secret management.
- Reports include a disclaimer and are for decision support only.

## License
Specify a license (e.g., MIT). See `LICENSE` file if included.
